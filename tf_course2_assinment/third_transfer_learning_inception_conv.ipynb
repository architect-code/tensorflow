{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
    "# ATTENTION: Please use the provided epoch values when training.\n",
    "\n",
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 74, 74, 32)   864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 74, 74, 32)   96          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 74, 74, 32)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 72, 72, 32)   9216        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 72, 72, 32)   96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 72, 72, 32)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 72, 72, 64)   18432       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 72, 72, 64)   192         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 72, 72, 64)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 35, 35, 80)   240         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 35, 35, 80)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 33, 33, 192)  138240      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 33, 33, 192)  576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 33, 33, 192)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 16, 16, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 16, 16, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 16, 16, 96)   55296       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 16, 16, 48)   144         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 16, 16, 96)   288         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 16, 16, 48)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 16, 16, 96)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 16, 16, 64)   76800       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 16, 16, 96)   82944       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 16, 16, 64)   192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 16, 16, 64)   192         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 16, 16, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 16, 16, 32)   96          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 16, 16, 64)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 16, 16, 64)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 16, 16, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 16, 16, 32)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_193[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 16, 16, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 16, 16, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 16, 16, 96)   55296       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 16, 16, 48)   144         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 16, 16, 96)   288         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 16, 16, 48)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 16, 16, 96)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 16, 16, 64)   76800       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 16, 16, 96)   82944       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 16, 16, 64)   192         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 16, 16, 64)   192         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 16, 16, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 16, 16, 64)   192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 16, 16, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 16, 16, 64)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 16, 16, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 16, 16, 64)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 16, 16, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 16, 16, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 16, 16, 96)   55296       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 16, 16, 48)   144         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 16, 16, 96)   288         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 16, 16, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 16, 16, 96)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 16, 16, 64)   76800       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 16, 16, 96)   82944       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 16, 16, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 16, 16, 64)   192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 16, 16, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 16, 16, 64)   192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 16, 16, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 16, 16, 64)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 16, 16, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 16, 16, 64)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 16, 16, 64)   192         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 16, 16, 64)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 16, 16, 96)   55296       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 16, 16, 96)   288         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 16, 16, 96)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 7, 7, 96)     82944       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 7, 7, 384)    1152        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 7, 7, 96)     288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 7, 7, 384)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 7, 7, 96)     0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 7, 7, 128)    384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 7, 7, 128)    0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 7, 7, 128)    114688      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 7, 7, 128)    384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 7, 7, 128)    114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 7, 7, 128)    384         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 7, 7, 128)    384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 7, 7, 128)    0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 7, 7, 128)    0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 7, 7, 128)    114688      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 7, 7, 128)    114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 7, 7, 128)    384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 7, 7, 128)    384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 7, 7, 128)    0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 7, 7, 128)    0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 7, 7, 192)    172032      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 7, 7, 192)    172032      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 7, 7, 192)    576         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 7, 7, 192)    576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 7, 7, 192)    576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 7, 7, 192)    576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 7, 7, 192)    0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 7, 7, 192)    0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 7, 7, 192)    0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 7, 7, 192)    0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 7, 7, 160)    480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 7, 7, 160)    0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 7, 7, 160)    179200      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 7, 7, 160)    480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 7, 7, 160)    0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 7, 7, 160)    179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 7, 7, 160)    480         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 7, 7, 160)    480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 7, 7, 160)    0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 7, 7, 160)    0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 7, 7, 160)    179200      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 7, 7, 160)    179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 7, 7, 160)    480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 7, 7, 160)    480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 7, 7, 160)    0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 7, 7, 160)    0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 7, 7, 192)    215040      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 7, 7, 192)    215040      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 7, 7, 192)    576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 7, 7, 192)    576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 7, 7, 192)    576         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 7, 7, 192)    576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 7, 7, 192)    0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 7, 7, 192)    0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 7, 7, 192)    0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 7, 7, 192)    0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_228[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 7, 7, 160)    480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 7, 7, 160)    0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 7, 7, 160)    179200      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 7, 7, 160)    480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 7, 7, 160)    0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 7, 7, 160)    179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 7, 7, 160)    480         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 7, 7, 160)    480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 7, 7, 160)    0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 7, 7, 160)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 7, 7, 160)    179200      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 7, 7, 160)    179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 7, 7, 160)    480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 7, 7, 160)    480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 7, 7, 160)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 7, 7, 160)    0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 7, 7, 192)    215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 7, 7, 192)    215040      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 7, 7, 192)    576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 7, 7, 192)    576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 7, 7, 192)    576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 7, 7, 192)    576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 7, 7, 192)    0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 7, 7, 192)    0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 7, 7, 192)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 7, 7, 192)    0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 7, 7, 192)    576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 7, 7, 192)    0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 7, 7, 192)    258048      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 7, 7, 192)    576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 7, 7, 192)    0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 7, 7, 192)    258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 7, 7, 192)    576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 7, 7, 192)    576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 7, 7, 192)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 7, 7, 192)    0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 7, 7, 192)    258048      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 7, 7, 192)    258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 7, 7, 192)    576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 7, 7, 192)    576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 7, 7, 192)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 7, 7, 192)    0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 7, 7, 192)    258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 7, 7, 192)    258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 7, 7, 192)    576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 7, 7, 192)    576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 7, 7, 192)    576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 7, 7, 192)    576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 7, 7, 192)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 7, 7, 192)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 7, 7, 192)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 7, 7, 192)    0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 7, 7, 192)    576         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 7, 7, 192)    0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 7, 7, 192)    258048      activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 7, 7, 192)    576         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 7, 7, 192)    0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 7, 7, 192)    258048      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 7, 7, 192)    576         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 7, 7, 192)    576         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 7, 7, 192)    0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 7, 7, 192)    0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 3, 3, 320)    552960      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 3, 3, 192)    331776      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 3, 3, 320)    960         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 3, 3, 192)    576         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 3, 3, 320)    0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 3, 3, 192)    0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_259[0][0]             \n",
      "                                                                 activation_263[0][0]             \n",
      "                                                                 max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 3, 3, 448)    1344        conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 3, 3, 448)    0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 3, 3, 384)    1548288     activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 3, 3, 384)    1152        conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 3, 3, 384)    1152        conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 3, 3, 384)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 3, 3, 384)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 3, 3, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 3, 3, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 3, 3, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 3, 3, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 3, 3, 384)    1152        conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 3, 3, 384)    1152        conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 3, 3, 384)    1152        conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 3, 3, 384)    1152        conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 3, 3, 320)    960         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 3, 3, 384)    0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 3, 3, 384)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 3, 3, 384)    0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 3, 3, 384)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 3, 3, 192)    576         conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 3, 3, 320)    0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_266[0][0]             \n",
      "                                                                 activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3, 3, 768)    0           activation_270[0][0]             \n",
      "                                                                 activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 3, 3, 192)    0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_264[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 3, 3, 448)    1344        conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 3, 3, 448)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 3, 3, 384)    1548288     activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 3, 3, 384)    1152        conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 3, 3, 384)    1152        conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 3, 3, 384)    0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 3, 3, 384)    0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 3, 3, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 3, 3, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 3, 3, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 3, 3, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 3, 3, 384)    1152        conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 3, 3, 384)    1152        conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 3, 3, 384)    1152        conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 3, 3, 384)    1152        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 3, 3, 320)    960         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 3, 3, 384)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 3, 3, 384)    0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 3, 3, 384)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 3, 3, 384)    0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
      "                                                                 activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 activation_281[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = path_inception\n",
    "\n",
    "pre_trained_model = InceptionV3(\n",
    "input_shape=(150,150,3), \n",
    "include_top=False,\n",
    "weights=None\n",
    ")\n",
    "\n",
    "# Your Code Here\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable=False\n",
    "  # Your Code Here\n",
    "  \n",
    "# Print the model summary\n",
    "pre_trained_model.summary()\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer(\"mixed7\") # Your Code Here)\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "    \n",
    "    # Your Code Here\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc')>0.97):\n",
    "      print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 74, 74, 32)   864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 74, 74, 32)   96          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 74, 74, 32)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 72, 72, 32)   9216        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 72, 72, 32)   96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 72, 72, 32)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 72, 72, 64)   18432       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 72, 72, 64)   192         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 72, 72, 64)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 35, 35, 80)   240         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 35, 35, 80)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 33, 33, 192)  138240      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 33, 33, 192)  576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 33, 33, 192)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 16, 16, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 16, 16, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 16, 16, 96)   55296       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 16, 16, 48)   144         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 16, 16, 96)   288         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 16, 16, 48)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 16, 16, 96)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 16, 16, 64)   76800       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 16, 16, 96)   82944       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 16, 16, 64)   192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 16, 16, 64)   192         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 16, 16, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 16, 16, 32)   96          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 16, 16, 64)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 16, 16, 64)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 16, 16, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 16, 16, 32)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_193[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 16, 16, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 16, 16, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 16, 16, 96)   55296       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 16, 16, 48)   144         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 16, 16, 96)   288         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 16, 16, 48)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 16, 16, 96)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 16, 16, 64)   76800       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 16, 16, 96)   82944       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 16, 16, 64)   192         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 16, 16, 64)   192         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 16, 16, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 16, 16, 64)   192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 16, 16, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 16, 16, 64)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 16, 16, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 16, 16, 64)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 16, 16, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 16, 16, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 16, 16, 96)   55296       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 16, 16, 48)   144         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 16, 16, 96)   288         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 16, 16, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 16, 16, 96)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 16, 16, 64)   76800       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 16, 16, 96)   82944       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 16, 16, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 16, 16, 64)   192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 16, 16, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 16, 16, 64)   192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 16, 16, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 16, 16, 64)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 16, 16, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 16, 16, 64)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 16, 16, 64)   192         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 16, 16, 64)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 16, 16, 96)   55296       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 16, 16, 96)   288         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 16, 16, 96)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 7, 7, 96)     82944       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 7, 7, 384)    1152        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 7, 7, 96)     288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 7, 7, 384)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 7, 7, 96)     0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 7, 7, 128)    384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 7, 7, 128)    0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 7, 7, 128)    114688      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 7, 7, 128)    384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 7, 7, 128)    114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 7, 7, 128)    384         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 7, 7, 128)    384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 7, 7, 128)    0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 7, 7, 128)    0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 7, 7, 128)    114688      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 7, 7, 128)    114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 7, 7, 128)    384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 7, 7, 128)    384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 7, 7, 128)    0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 7, 7, 128)    0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 7, 7, 192)    172032      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 7, 7, 192)    172032      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 7, 7, 192)    576         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 7, 7, 192)    576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 7, 7, 192)    576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 7, 7, 192)    576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 7, 7, 192)    0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 7, 7, 192)    0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 7, 7, 192)    0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 7, 7, 192)    0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 7, 7, 160)    480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 7, 7, 160)    0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 7, 7, 160)    179200      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 7, 7, 160)    480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 7, 7, 160)    0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 7, 7, 160)    179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 7, 7, 160)    480         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 7, 7, 160)    480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 7, 7, 160)    0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 7, 7, 160)    0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 7, 7, 160)    179200      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 7, 7, 160)    179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 7, 7, 160)    480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 7, 7, 160)    480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 7, 7, 160)    0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 7, 7, 160)    0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 7, 7, 192)    215040      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 7, 7, 192)    215040      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 7, 7, 192)    576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 7, 7, 192)    576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 7, 7, 192)    576         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 7, 7, 192)    576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 7, 7, 192)    0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 7, 7, 192)    0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 7, 7, 192)    0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 7, 7, 192)    0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_228[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 7, 7, 160)    480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 7, 7, 160)    0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 7, 7, 160)    179200      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 7, 7, 160)    480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 7, 7, 160)    0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 7, 7, 160)    179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 7, 7, 160)    480         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 7, 7, 160)    480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 7, 7, 160)    0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 7, 7, 160)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 7, 7, 160)    179200      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 7, 7, 160)    179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 7, 7, 160)    480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 7, 7, 160)    480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 7, 7, 160)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 7, 7, 160)    0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 7, 7, 192)    215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 7, 7, 192)    215040      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 7, 7, 192)    576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 7, 7, 192)    576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 7, 7, 192)    576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 7, 7, 192)    576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 7, 7, 192)    0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 7, 7, 192)    0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 7, 7, 192)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 7, 7, 192)    0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 7, 7, 192)    576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 7, 7, 192)    0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 7, 7, 192)    258048      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 7, 7, 192)    576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 7, 7, 192)    0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 7, 7, 192)    258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 7, 7, 192)    576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 7, 7, 192)    576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 7, 7, 192)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 7, 7, 192)    0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 7, 7, 192)    258048      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 7, 7, 192)    258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 7, 7, 192)    576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 7, 7, 192)    576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 7, 7, 192)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 7, 7, 192)    0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 7, 7, 192)    258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 7, 7, 192)    258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 7, 7, 192)    576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 7, 7, 192)    576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 7, 7, 192)    576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 7, 7, 192)    576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 7, 7, 192)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 7, 7, 192)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 7, 7, 192)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 7, 7, 192)    0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation=\"relu\")(x) # Your Code Here)(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation=\"sigmoid\")(x)           \n",
    "\n",
    "model = Model(pre_trained_model.input, x)# Your Code Here, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = \"binary_crossentropy\", # Your Code Here, \n",
    "              metrics = [\"acc\"]) # Your Code Here)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree('/tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "train_horses_dir = os.path.join(train_dir, \"horses\") # Your Code Here\n",
    "train_humans_dir = os.path.join(train_dir, \"humans\") # Your Code Here\n",
    "validation_horses_dir =  os.path.join(validation_dir, \"horses\") # Your Code Here\n",
    "validation_humans_dir =  os.path.join(validation_dir, \"humans\") # Your Code Here\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir) # Your Code Here\n",
    "train_humans_fnames = os.listdir(train_humans_dir) # Your Code Here\n",
    "validation_horses_fnames =  os.listdir(validation_horses_dir) # Your Code Here\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir) # Your Code Here\n",
    "\n",
    "print( len(train_horses_fnames))# Your Code Here)\n",
    "print( len(train_humans_fnames) ) # Your Code Here)\n",
    "print(len(validation_horses_fnames)) # Your Code Here)\n",
    "print(len(validation_humans_fnames)) # Your Code Here)\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator( rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode=\"nearest\"                                                \n",
    "                                  ) # Your Code Here)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator( rescale=1./255)  # Your Code Here )\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode=\"binary\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Your Code Here)     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory( \n",
    " validation_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode=\"binary\")   \n",
    "\n",
    "    # Your Code Here)\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "52/52 [==============================] - 42s 805ms/step - loss: 0.1693 - acc: 0.9299 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 2/3\n",
      "52/52 [==============================] - 38s 729ms/step - loss: 0.1151 - acc: 0.9552 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 3/3\n",
      "51/52 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9831\n",
      "Reached 97.0% accuracy so cancelling training!\n",
      "52/52 [==============================] - 40s 767ms/step - loss: 0.0568 - acc: 0.9834 - val_loss: 0.0052 - val_acc: 0.9961\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 97% accuracy\n",
    "\n",
    "callbacks = myCallback() # Your Code Here\n",
    "history = model.fit_generator(\n",
    "train_generator,\n",
    "    epochs=3,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1,\n",
    "    callbacks= [callbacks]\n",
    ") \n",
    "    \n",
    "    # Your Code Here (set epochs = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This will free up resources for your fellow learners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.session.delete();\n",
    "window.onbeforeunload = null\n",
    "setTimeout(function() { window.close(); }, 1000);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
